# ðŸ–¼ï¸ Image Classification on CIFAR-10: From Scratch to Transfer Learning ðŸš€  
*How far can we push accuracy on CIFAR-10 by evolving from a simple CNN to cutting-edge pretrained models?*  

---

## ðŸ“Š Dataset Description  
- **Dataset**: [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)  
- **Size**: 60,000 color images (32x32 pixels) across **10 balanced classes**:  
  âœˆï¸ airplane | ðŸš— automobile | ðŸ¦ bird | ðŸ± cat | ðŸ¦Œ deer | ðŸ¶ dog | ðŸ¸ frog | ðŸ´ horse | ðŸš¢ ship | ðŸšš truck  
- **Split**: 50,000 training images + 10,000 testing images.  
- **Challenges**:  
  - Low-resolution images â†’ harder to extract strong features.  
  - Some categories are very similar (cat vs dog, car vs truck).  

---

## ðŸŽ¯ Research Goal  
This project set out to answer a key question:  

ðŸ‘‰ *What happens when we compare custom-built CNNs against modern transfer learning models on CIFAR-10?*  

Unlike many projects that stop at a single CNN, this work explores the **evolution of improvements** step by step:  

1. **Baseline CNN (from scratch)** â€” a simple ConvNet to establish a starting point.  
2. **Deeper CNN** â€” added more convolutional layers and dropout to extract richer features.  
3. **BatchNorm, Dropout & Regularization** â€” introduced Batch Normalization, GlobalAveragePooling and L2 weight decay to stabilize and regularize training.  
4. **Early Stopping** â€” tuned training with early stopping to avoid overfitting.  
5. **Data Augmentation** â€” applied random rotations, flips and shifts to improve robustness and generalization.  
6. **Transfer Learning (MobileNetV2 variants)** â€” benchmarked several MobileNetV2 head/fine-tuning strategies to leverage pretrained ImageNet features. 

---

## ðŸ› ï¸ Methodology & Models  

### ðŸ”¹ Custom CNNs  
- **Baseline CNN**  
  - Conv2D(32) â†’ MaxPool â†’ Conv2D(64) â†’ MaxPool â†’ Dense(128) â†’ Softmax  
  - **Test Accuracy**: ~68.9%  

- **Deeper CNN + Dropout**  
  - Added Conv2D(128), Dense(256), Dropout(0.5)  
  - **Test Accuracy**: **73.4%** | Train Acc: 85%  

- **CNN + BatchNorm + GAP**  
  - Added BatchNormalization + GlobalAveragePooling  
  - **Test Accuracy**: **73.1%** | Train Acc: 91%  

- **CNN + Regularizer (L2)**  
  - Added weight decay regularization  
  - **Test Accuracy**: **72.5%** | Train Acc: 93%  

- **CNN + Early Stopping**  
  - Hyperparameter tuning + early stopping  
  - **Test Accuracy**: **72.9%** | Train Acc: 94%  

- **CNN + Data Augmentation**  
  - Rotations, flips, shifts  
  - **Test Accuracy**: **76.9%** âœ… | Train Acc: 74%  

---

### ðŸ”¹ Transfer Learning  

#### MobileNetV2 Experiments  
- **MobileNetV2.1** â†’ GAP â†’ Dense(128, ReLU) â†’ Dense(10, Softmax)  
  - Training: 5 epochs, batch size 64  
  - **Test Accuracy**: **86.6%** âœ…  

- **MobileNetV2.2** â†’ GAP â†’ Dropout(0.3) â†’ Dense(10, Softmax)  
  - Training: Frozen base, 10 epochs, default batch size  
  - **Test Accuracy**: **85.6%**  

- **MobileNetV2.3** â†’ Same as V2.2, batch size 64  
  - Training: Frozen base, 10 epochs  
  - **Test Accuracy**: **85.6%**    

---

## ðŸ“ˆ Results Overview  

| Model Version                       | Test Accuracy | Training Accuracy |
|-------------------------------------|---------------|------------------|
| Baseline CNN (2 Conv layers)        | ~68.9%        | ~84%             |
| Deeper CNN (3 Conv + Dropout)       | **73.4%**     | 85%              |
| CNN + BatchNorm + GAP               | **73.1%**     | 91%              |
| CNN + Regularizer (L2)              | **72.5%**     | 93%              |
| CNN + Early Stopping                | **72.9%**     | 94%              |
| CNN + Data Augmentation             | **76.9%** âœ…  | 74%              |
|-------------------------------------|---------------|------------------|
| MobileNetV2.1 (Dense Head)          | **86.6%** âœ…  |                 |
| MobileNetV2.2 (Dropout Head)        | **85.6%**     | -               |
| MobileNetV2.3 (Dropout + batch=64)  | **85.6%**     | -                |

---

## ðŸ’¡ Key Insights  

- ðŸ“ˆ Custom CNNs improved step by step, but plateaued around ~77%.  
- ðŸ§  Transfer learning (MobileNetV2) **significantly outperformed scratch CNNs**.  
- ðŸ” **MobileNetV2.1** achieved state-of-the-art performance on CIFAR-10 at **86.6%**.  
- ðŸ±ðŸ¶ Most misclassifications: **cats vs dogs**, **cars vs trucks**.  

---

## âš™ï¸ How to Reproduce  

1.**Clone the repo**  
```bash
git clone https://nataliadominguez99/Image-classification-using-CNN-and-Transfer-Learning.git
cd your-repo
```
2. **Navigate to the project folder**
   ```bash
    cd Image-classification-using-CNN-and-Transfer-Learning

3. **Open the Jupyter Notebook**
- If you use Jupyter Notebook:
   ```bash
   jupyter notebook "ProjectCifar.ipynb"
- Or, open it in VSCode by double-clicking the file or using:
   ```bash
    code "ProjectCifar.ipynb"

4. **Run all cells**
- Select Cell > Run All in Jupyter Notebook or VSCode to reproduce the analysis.
---

## Install dependencies

```bash
pip install -r requirements.txt
```
---

## Run the notebook  

Open `ProjectCifar.ipynb` in Jupyter Notebook and run all cells.  

- **Python version**: 3.10+  
- **Key Libraries**: TensorFlow/Keras, NumPy, Pandas, Matplotlib, Seaborn, Scikit-learn

---

## ðŸš€ Next Steps  

- Extend to **CIFAR-100** (100 classes, more fine-grained).  
- Try larger **transfer learning models** (ResNet50, EfficientNetB7).  
- Deploy as a **Streamlit/Flask web app** for interactive demos.  
- Experiment with **ensembling multiple CNNs + transfer models**.

---

## ðŸ“‚ Repository Structure
```bash
â”œâ”€â”€ ProjectCifar.ipynb # Jupyter Notebook with full pipeline
â”œâ”€â”€ requirements.txt   # Dependencies for reproduction
â”œâ”€â”€ Image classification using CNN and Transfer Learning.pptx  # Project presentation slides
â””â”€â”€ README.md          # Project documentation
```
